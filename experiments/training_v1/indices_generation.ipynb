{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from langgfm.data.graph_generator import InputGraphGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall indices.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbn_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/OgbnArxiv_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['ogbn_arxiv'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wiki_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/WikiCS_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['wiki_cs'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/Twitch_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['twitch'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re_europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"re_europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['re_europe'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oag_scholar_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"oag_scholar_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['oag_scholar_interest'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fb15k237 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split= json.load(open('experiments/training_v1/benchmark_splits/FB15K237_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_generator.utils.graph_utils import get_multiplex_id_by_edge_idx\n",
    "generator = InputGraphGenerator.create(\"fb15k237\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for idx in split['train']:\n",
    "    src, dst = generator.graph.edge_index[:,idx].tolist()\n",
    "    multiplex_id = get_multiplex_id_by_edge_idx(idx,generator.graph.edge_index)\n",
    "    samples.append((src,dst,multiplex_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['fb15k237'] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbl_vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split= json.load(open('experiments/training_v1/benchmark_splits/OgblVessel_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_generator.utils.graph_utils import get_multiplex_id_by_edge_idx\n",
    "generator = InputGraphGenerator.create(\"ogbl_vessel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for idx in split['train']:\n",
    "    sample = generator.all_samples[idx]\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['ogbl_vessel'] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## movielens1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langgfm.data.graph_generator import OgblVesselGraphGenerator\n",
    "generator = InputGraphGenerator.create(\"movielens1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['movielens1m'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stack_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 17:32:32,083 - DEBUG - [stack_elec_generator.py:30] Counter([(row['u'], row['i']) for row_idx, row in self.edge_list.iterrows()]).most_common(10)=[((np.int64(5319), np.int64(81668)), 43), ((np.int64(62), np.int64(81668)), 34), ((np.int64(6251), np.int64(84896)), 31), ((np.int64(11406), np.int64(83311)), 28), ((np.int64(2484), np.int64(92160)), 27), ((np.int64(773), np.int64(68432)), 27), ((np.int64(5319), np.int64(99666)), 26), ((np.int64(3955), np.int64(99452)), 26), ((np.int64(3035), np.int64(76281)), 25), ((np.int64(16112), np.int64(109820)), 25)]\n"
     ]
    }
   ],
   "source": [
    "generator = InputGraphGenerator.create(\"stack_elec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['stack_elec'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yelp_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"yelp_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30841,  1771])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.hetero_data[\"user\", \"review\", \"business\"].edge_index[:,12693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['yelp_review'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_train_idx = json.load(open('experiments/training_v1/benchmark_splits/ugm@YelpReviewGeneration@@@main_max_length=16000_Table_samples_train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sample['fname'] for sample in old_train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/Fingerprint_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['fingerprint'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/BACE_ugm_split.json'))\n",
    "indices['bace'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"esol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['esol'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explagraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"explagraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['explagraphs'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chebi20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"chebi20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['chebi20'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsbeautifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_mini = {k:v[:10] for k,v in indices.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ogbn_arxiv\": [122169, 4648, 132020, 42550, 83465, 77953, 50753, 81032, 40188, 157311],\n",
      "    \"wiki_cs\": [7527, 3861, 898, 5324, 6859, 8588, 11696, 10954, 9147, 10176],\n",
      "    \"twitch\": [11630, 64692, 39769, 99131, 56370, 145128, 15971, 167806, 138416, 132366],\n",
      "    \"re_europe\": [462289, 269321, 774424, 1505154, 704182, 1319287, 1493431, 953275, 396018, 1566885],\n",
      "    \"oag_scholar_interest\": [955939, 3114645, 1750864, 284913, 2283885, 45385, 147605, 3146596, 376143, 45275],\n",
      "    \"fb15k237\": [[11528, 2949, 1], [4430, 6021, 1], [10910, 7355, 0], [14153, 10398, 0], [4905, 12076, 0], [3943, 2314, 0], [12577, 310, 0], [11989, 689, 0], [2303, 14122, 0], [13595, 5462, 0]],\n",
      "    \"ogbl_vessel\": [[1220018, 1210418], [763068, 758718], [2425296, 2427986], [665292, 671297], [1409060, 1406480], [1638884, 1660322], [2006733, 2028276], [780206, 714914], [3247056, 3250557], [359711, 359714]],\n",
      "    \"movielens1m\": [[1003, 1287], [5249, 2174], [5404, 1828], [5326, 2693], [4978, 1006], [4807, 1977], [150, 3487], [3270, 2322], [1138, 2470], [3110, 538]],\n",
      "    \"stack_elec\": [[551, 251572], [128, 313721], [968, 112201], [62, 112850], [27, 228547], [128, 134985], [3403, 102104], [51, 170561], [18663, 133151], [51, 311868]],\n",
      "    \"yelp_review\": [[1671342, 107559, 0], [42297, 23581, 0], [621404, 113141, 0], [32313, 107205, 0], [604368, 120871, 0], [27415, 93836, 1], [1850715, 149693, 0], [772870, 16987, 0], [180902, 86346, 0], [270113, 95715, 0]],\n",
      "    \"fingerprint\": [1631, 465, 1130, 1499, 1473, 1810, 1180, 1024, 160, 529],\n",
      "    \"bace\": [1190, 437, 366, 241, 426, 1256, 617, 1435, 799, 1110],\n",
      "    \"esol\": [777, 703, 863, 633, 992, 782, 1086, 419, 242, 366],\n",
      "    \"explagraphs\": [2259, 2693, 504, 427, 733, 2176, 1911, 1478, 2438, 367],\n",
      "    \"chebi20\": [126559185, 7172291, 3030, 752, 101297699, 87642, 21145099, 56833383, 13807318, 442868]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 转换为字符串\n",
    "import re\n",
    "json_string = json.dumps(indices_mini)\n",
    "# print(f\"{json_string=}\")\n",
    "# # 设定 jsbeautifier 的格式化参数\n",
    "# opts = jsbeautifier.default_options()\n",
    "# opts.indent_size = 2  # 设置缩进大小\n",
    "# opts.wrap_line_length = 0  # 让列表中的列表不换行\n",
    "# opts.keep_array_indentation = True  # 保持数组缩进格式\n",
    "\n",
    "\n",
    "# 使用 jsbeautifier 美化 JSON\n",
    "formatted_json = jsbeautifier.beautify(json_string)\n",
    "# print(formatted_json)\n",
    "\n",
    "# formatted_json = re.sub(r'\\[\\n\\s+\\[([^]]+)]\\n\\s+]', r'[[\\1]]', formatted_json)\n",
    "# 处理数组换行问题\n",
    "# 正则替换，去除换行\n",
    "formatted_json = re.sub(r\"\\],\\s*\\n\\s*\\[\", \"], [\", formatted_json)\n",
    "\n",
    "# 替换 \"[\\n        [\" 为 \"[[\"\n",
    "formatted_json = re.sub(r'\\[\\s*\\n\\s*\\[', '[[', formatted_json)\n",
    "\n",
    "# 替换 \"]\\n    ]\" 为 \"]]\"\n",
    "formatted_json = re.sub(r'\\]\\s*\\n\\s*\\]', ']]', formatted_json)\n",
    "\n",
    "print(formatted_json)\n",
    "\n",
    "# 存储到本地文件\n",
    "with open(\"/home/tlin4/projects/LangGFM/experiments/training_v1/indices_semantic.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(formatted_json)\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"/home/tlin4/projects/LangGFM/experiments/training_v1/indices_semantic.json\", \"w\") as f:\n",
    "#     json_str = json.dumps(indices, indent=4, separators=(',', ': '))\n",
    "#     json_str = re.sub(r'\\[\\n\\s+(\\[.*?\\])\\n\\s+\\]', r'[\\1]', json_str)\n",
    "#     f.write(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"fb15k237\": [[11528, 2949, 1], [4430, 6021, 1], [10910, 7355, 0], [14153, 10398, 0], [4905, 12076, 0], [3943, 2314, 0], [12577, 310, 0], [11989, 689, 0], [2303, 14122, 0], [13595, 5462, 0]],\n",
      "    \"ogbl_vessel\": [[1220018, 1210418], [763068, 758718], [2425296, 2427986], [665292, 671297], [1409060, 1406480], [1638884, 1660322]]\n",
      "}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
