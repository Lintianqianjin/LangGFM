{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from langgfm.data.graph_generator import InputGraphGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputGraphGenerator.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices = dict()\n",
    "for dataset in InputGraphGenerator.registry:\n",
    "    if dataset in {\"usa_airport\"}:\n",
    "        continue\n",
    "    print(dataset)\n",
    "    generator = InputGraphGenerator.create(dataset)\n",
    "    all_samples = generator.all_samples\n",
    "    samples = random.sample(all_samples, min(5000, len(all_samples)))\n",
    "    indices[dataset] = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.utils.io import save_beautiful_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_beautiful_json(indices, \"./experiments/training_v1/indice_min(5k_datasetsize).json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall indices.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbn_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/OgbnArxiv_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['ogbn_arxiv'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wiki_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/WikiCS_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['wiki_cs'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## twitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/Twitch_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['twitch'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re_europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"re_europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['re_europe'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oag_scholar_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"oag_scholar_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['oag_scholar_interest'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fb15k237 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split= json.load(open('experiments/training_v1/benchmark_splits/FB15K237_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_generator.utils.graph_utils import get_multiplex_id_by_edge_idx\n",
    "generator = InputGraphGenerator.create(\"fb15k237\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for idx in split['train']:\n",
    "    src, dst = generator.graph.edge_index[:,idx].tolist()\n",
    "    multiplex_id = get_multiplex_id_by_edge_idx(idx,generator.graph.edge_index)\n",
    "    samples.append((src,dst,multiplex_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['fb15k237'] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ogbl_vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split= json.load(open('experiments/training_v1/benchmark_splits/OgblVessel_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_generator.utils.graph_utils import get_multiplex_id_by_edge_idx\n",
    "generator = InputGraphGenerator.create(\"ogbl_vessel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for idx in split['train']:\n",
    "    sample = generator.all_samples[idx]\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['ogbl_vessel'] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## movielens1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langgfm.data.graph_generator import OgblVesselGraphGenerator\n",
    "generator = InputGraphGenerator.create(\"movielens1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['movielens1m'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stack_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"stack_elec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['stack_elec'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yelp_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"yelp_review\", num_hops=1, sampling=True, neighbor_size = [50], random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, metadata = generator.generate_graph([143317, 6874, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_text_transformation.nxg_to_text import GraphTextualizer\n",
    "# 使用 GraphTextualizer\n",
    "textualizer = GraphTextualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出为 JSON 格式\n",
    "json_text = textualizer.export(G, format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_old = json.load(open(\"/home/tlin4/projects/LangGFM/experiments/training_v1/indices_semantic.json\"))['yelp_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.hetero_data[\"user\", \"review\", \"business\"].edge_index[:,12693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['yelp_review'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_train_idx = json.load(open('experiments/training_v1/benchmark_splits/ugm@YelpReviewGeneration@@@main_max_length=16000_Table_samples_train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sample['fname'] for sample in old_train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/Fingerprint_ugm_split.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"fingerprint\")\n",
    "indices['fingerprint'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = json.load(open('experiments/training_v1/benchmark_splits/BACE_ugm_split.json'))\n",
    "indices['bace'] = split['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"esol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['esol'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explagraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"explagraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['explagraphs'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chebi20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"chebi20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_old = json.load(open(\"/home/tlin4/projects/LangGFM/experiments/training_v1/indices_semantic.json\"))['chebi20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['chebi20'] = random.sample(list(generator.all_samples),k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(list(set(random.sample(list(generator.all_samples),k=500) )- set(indices_old)),k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsbeautifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_mini = {k:v[:10] for k,v in indices.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为字符串\n",
    "import re\n",
    "json_string = json.dumps(indices)\n",
    "# print(f\"{json_string=}\")\n",
    "# # 设定 jsbeautifier 的格式化参数\n",
    "# opts = jsbeautifier.default_options()\n",
    "# opts.indent_size = 2  # 设置缩进大小\n",
    "# opts.wrap_line_length = 0  # 让列表中的列表不换行\n",
    "# opts.keep_array_indentation = True  # 保持数组缩进格式\n",
    "\n",
    "\n",
    "# 使用 jsbeautifier 美化 JSON\n",
    "formatted_json = jsbeautifier.beautify(json_string)\n",
    "# print(formatted_json)\n",
    "\n",
    "# formatted_json = re.sub(r'\\[\\n\\s+\\[([^]]+)]\\n\\s+]', r'[[\\1]]', formatted_json)\n",
    "# 处理数组换行问题\n",
    "# 正则替换，去除换行\n",
    "formatted_json = re.sub(r\"\\],\\s*\\n\\s*\\[\", \"], [\", formatted_json)\n",
    "\n",
    "# 替换 \"[\\n        [\" 为 \"[[\"\n",
    "formatted_json = re.sub(r'\\[\\s*\\n\\s*\\[', '[[', formatted_json)\n",
    "\n",
    "# 替换 \"]\\n    ]\" 为 \"]]\"\n",
    "formatted_json = re.sub(r'\\]\\s*\\n\\s*\\]', ']]', formatted_json)\n",
    "\n",
    "print(formatted_json)\n",
    "\n",
    "# 存储到本地文件\n",
    "with open(\"projects/LangGFM/experiments/training_v1/indices_semantic.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(formatted_json)\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"/home/tlin4/projects/LangGFM/experiments/training_v1/indices_semantic.json\", \"w\") as f:\n",
    "#     json_str = json.dumps(indices, indent=4, separators=(',', ': '))\n",
    "#     json_str = re.sub(r'\\[\\n\\s+(\\[.*?\\])\\n\\s+\\]', r'[\\1]', json_str)\n",
    "#     f.write(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
