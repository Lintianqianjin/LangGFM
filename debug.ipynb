{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_generator import InputGraphGenerator\n",
    "generator = InputGraphGenerator.create(\"oag_scholar_interest\")\n",
    "G, metadata = generator.generate_graph(sample_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InputGraphGenerator.create(\"oag_scholar_interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.hetero_graph[\"author\", \"writes\", \"paper\"].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, metadata = generator.generate_graph(sample_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgfm.data.graph_generator.utils.sampling import generate_node_centric_k_hop_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,nodes,_ = generate_node_centric_k_hop_subgraph(generator.graph, sample_id=1,num_hops=1,neighbor_size=10,random_seed=42,sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,nodes,_ = generate_node_centric_k_hop_subgraph(generator.graph, sample_id=nodes,num_hops=1,neighbor_size=10,random_seed=42,sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.graph.edge_index.T[torch.logical_or(generator.graph.edge_index[0]==1,generator.graph.edge_index[1]==3180866)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.graph.edge_index.T[generator.graph.edge_index[1]==3180866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "# Generate k-hop subgraph without sampling\n",
    "src_to_tgt_subset, src_to_tgt_edge_index, _, src_to_tgt_edge_mask = k_hop_subgraph(\n",
    "    node_idx=1, num_hops=2, edge_index=generator.graph.edge_index,\n",
    "    relabel_nodes=False, flow='source_to_target', directed=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# edge_index = torch.tensor([[0, 1, 2, 3, 4, 5],\n",
    "#                            [2, 2, 4, 4, 6, 6]])\n",
    "edge_index = torch.tensor([[2, 2, 4, 4, 6, 6],\n",
    "                            [0, 1, 2, 3, 4, 5]])\n",
    "# subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "#     6, 2, edge_index, flow='source_to_target', num_nodes=None,)\n",
    "subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "    6, 2, edge_index, flow='target_to_source', num_nodes=None,)\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from typing import Optional, Union, List\n",
    "\n",
    "def to_undirected(edge_index: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a directed graph to an undirected one by adding reverse edges.\n",
    "    For each edge (u, v), it also adds (v, u).\n",
    "    If your graph is already undirected, you can return the original edge_index directly.\n",
    "    \"\"\"\n",
    "    row, col = edge_index\n",
    "    reversed_edges = torch.stack([col, row], dim=0)\n",
    "    return torch.cat([edge_index, reversed_edges], dim=1)\n",
    "\n",
    "def build_csr(edge_index: torch.Tensor, num_nodes: int):\n",
    "    \"\"\"\n",
    "    Builds a CSR-like structure from edge_index (2, E):\n",
    "      - row_ptr[i] gives the start position of node i's neighbors in col_ind\n",
    "      - col_ind[row_ptr[i]: row_ptr[i+1]] contains all neighbors of node i\n",
    "    The input edge_index is assumed to be undirected or will be converted by calling to_undirected().\n",
    "    \"\"\"\n",
    "    # Convert to undirected (if your original graph is directed)\n",
    "    edge_index_undirected = to_undirected(edge_index)\n",
    "\n",
    "    row, col = edge_index_undirected\n",
    "    # Sort edges by row so that all edges from the same source node are contiguous\n",
    "    sorted_idx = row.argsort()\n",
    "    row = row[sorted_idx]\n",
    "    col = col[sorted_idx]\n",
    "\n",
    "    # Build row_ptr: the cumulative count of edges for each node\n",
    "    row_counts = torch.bincount(row, minlength=num_nodes)\n",
    "    row_ptr = torch.zeros(num_nodes + 1, dtype=torch.long)\n",
    "    row_ptr[1:] = torch.cumsum(row_counts, dim=0)\n",
    "\n",
    "    return row_ptr, col\n",
    "\n",
    "def get_khop_subgraph(\n",
    "    edge_index: torch.Tensor,\n",
    "    node_idx: Union[int, List[int], torch.Tensor],\n",
    "    num_hops: int,\n",
    "    max_neighbors_per_hop: Optional[Union[int, List[int]]] = None,\n",
    "    sampling: bool = False,\n",
    "    random_seed: Optional[int] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a layer-wise BFS up to num_hops steps from the seed node(s) and optionally samples neighbors per node.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_index : torch.Tensor, shape (2, E)\n",
    "        The edge list of the graph. If the graph is directed, it should be converted first or handled by to_undirected().\n",
    "    node_idx : int, list[int], or 1D torch.Tensor[int]\n",
    "        The starting node(s) for BFS.\n",
    "    num_hops : int\n",
    "        The maximum number of BFS layers.\n",
    "    max_neighbors_per_hop : None or int or list[int], optional\n",
    "        - When sampling=True, this parameter controls the maximum number of neighbors retained per node per hop.\n",
    "          * If an int is given, the same limit is used for every hop.\n",
    "          * If a list[int] is given, each hop uses a potentially different limit. For example, [15, 5] means:\n",
    "            - For the 1st hop, each node keeps at most 15 neighbors.\n",
    "            - For the 2nd hop, each node keeps at most 5 neighbors.\n",
    "          * If None, no limit is applied, keeping all neighbors.\n",
    "        - When sampling=False, this parameter is ignored and all neighbors are kept.\n",
    "    sampling : bool\n",
    "        Whether to perform neighbor sampling (True) or not (False).\n",
    "    random_seed : int or None\n",
    "        If set, a random seed is applied (both Python and PyTorch) for reproducible sampling.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sub_graph_nodes : set[int]\n",
    "        The set of nodes visited by BFS, intersected with nodes from edge_index[0].\n",
    "    sub_graph_edge_mask : torch.BoolTensor of shape (E,)\n",
    "        A boolean mask for the original edges. True means the edge belongs to the k-hop subgraph (both endpoints visited).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This approach uses a BFS with a frontier set of nodes at each hop. When sampling=True, each node's neighbor list\n",
    "    is randomly truncated (if longer than the specified limit). Otherwise, the full neighbor list is used.\n",
    "    \"\"\"\n",
    "    # 1) Convert node_idx into a list of integers\n",
    "    if isinstance(node_idx, int):\n",
    "        start_nodes = [node_idx]\n",
    "    elif isinstance(node_idx, list):\n",
    "        start_nodes = node_idx\n",
    "    elif isinstance(node_idx, torch.Tensor):\n",
    "        start_nodes = node_idx.tolist()\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported type for node_idx: {type(node_idx)}\")\n",
    "\n",
    "    # 2) Set random seed if specified\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "    # 3) Determine the number of nodes in the graph\n",
    "    all_nodes = torch.cat([edge_index[0], edge_index[1]], dim=0)\n",
    "    num_nodes = int(all_nodes.max().item()) + 1\n",
    "\n",
    "    # 4) Build the CSR-like structure\n",
    "    row_ptr, col_ind = build_csr(edge_index, num_nodes)\n",
    "\n",
    "    # 5) Initialize BFS\n",
    "    visited = set(start_nodes)\n",
    "    frontier = set(start_nodes)\n",
    "\n",
    "    # Helper function: get the sampling limit for the current hop\n",
    "    def get_limit_for_hop(hop_idx: int) -> Optional[int]:\n",
    "        # If sampling=False, no limit\n",
    "        if not sampling:\n",
    "            return None\n",
    "\n",
    "        # If sampling=True but max_neighbors_per_hop is None, keep all\n",
    "        if max_neighbors_per_hop is None:\n",
    "            return None\n",
    "\n",
    "        # If max_neighbors_per_hop is a single int, apply it to all hops\n",
    "        if isinstance(max_neighbors_per_hop, int):\n",
    "            return max_neighbors_per_hop\n",
    "\n",
    "        # If max_neighbors_per_hop is a list, index by hop\n",
    "        if hop_idx < len(max_neighbors_per_hop):\n",
    "            return max_neighbors_per_hop[hop_idx]\n",
    "        else:\n",
    "            # If out of range, we could return the last or None\n",
    "            return max_neighbors_per_hop[-1]\n",
    "\n",
    "    # 6) Layer-wise BFS\n",
    "    for hop in range(num_hops):\n",
    "        if not frontier:\n",
    "            break\n",
    "        next_frontier = set()\n",
    "        limit_this_hop = get_limit_for_hop(hop)\n",
    "\n",
    "        for node in frontier:\n",
    "            u = int(node)\n",
    "            start = row_ptr[u].item()\n",
    "            end = row_ptr[u+1].item()\n",
    "            neighbors = col_ind[start:end]\n",
    "\n",
    "            # If we have a limit for neighbors, randomly sample\n",
    "            if limit_this_hop is not None and len(neighbors) > limit_this_hop:\n",
    "                perm = torch.randperm(len(neighbors))[:limit_this_hop]\n",
    "                neighbors = neighbors[perm]\n",
    "\n",
    "            for nbr in neighbors.tolist():\n",
    "                if nbr not in visited:\n",
    "                    visited.add(nbr)\n",
    "                    next_frontier.add(nbr)\n",
    "\n",
    "        frontier = next_frontier\n",
    "\n",
    "    # 7) Build subgraph nodes and edge mask\n",
    "    # Intersect visited nodes with the nodes in edge_index[0]\n",
    "    row0_nodes = set(edge_index[0].tolist())\n",
    "    sub_graph_nodes = visited.intersection(row0_nodes)\n",
    "\n",
    "    # Create a boolean mask for edges whose both endpoints are visited\n",
    "    visited_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    for n in visited:\n",
    "        visited_mask[n] = True\n",
    "\n",
    "    edge_u = edge_index[0]\n",
    "    edge_v = edge_index[1]\n",
    "    sub_graph_edge_mask = visited_mask[edge_u] & visited_mask[edge_v]\n",
    "\n",
    "    return sub_graph_nodes, sub_graph_edge_mask\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "edge_index = torch.tensor([\n",
    "    [0,       1,       2,       3,       4,       7127060,  5],\n",
    "    [3180866, 3180866, 3180866, 3180866, 3180866, 3180866,  199811]\n",
    "])\n",
    "node_idx = [1,5]\n",
    "num_hops = 2\n",
    "\n",
    "print(\"==== sampling=False ====\")\n",
    "sub_nodes_no_sample, sub_mask_no_sample = get_khop_subgraph(\n",
    "    edge_index, \n",
    "    node_idx, \n",
    "    num_hops,\n",
    "    max_neighbors_per_hop=[15, 5],\n",
    "    sampling=False,       # Disable sampling\n",
    "    random_seed=42\n",
    ")\n",
    "print(\"sub_graph_nodes =\", sub_nodes_no_sample)\n",
    "print(\"sub_graph_edge_mask =\", sub_mask_no_sample)\n",
    "\n",
    "print(\"==== sampling=True ====\")\n",
    "sub_nodes_sample, sub_mask_sample = get_khop_subgraph(\n",
    "    edge_index, \n",
    "    node_idx, \n",
    "    num_hops,\n",
    "    max_neighbors_per_hop=[3, 2],\n",
    "    sampling=True,        # Enable sampling\n",
    "    random_seed=0\n",
    ")\n",
    "print(\"sub_graph_nodes =\", sub_nodes_sample)\n",
    "print(\"sub_graph_edge_mask =\", sub_mask_sample)\n",
    "\n",
    "\n",
    "# # edge_index = generator.graph.edge_index.T[torch.logical_or(generator.graph.edge_index[0]==1,generator.graph.edge_index[1]==3180866)].T\n",
    "# # edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n",
    "# # print(edge_index)\n",
    "# edge_index = torch.tensor([[ 0,       1,       2,       3,       4, 7127060],\n",
    "#                             [3180866, 3180866, 3180866, 3180866, 3180866, 3180866]])\n",
    "# # subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "# #     1, 2, edge_index,flow=\"target_to_source\")\n",
    "# subset, _, _, edge_mask = k_hop_subgraph(\n",
    "#     1, 3, edge_index,flow=\"target_to_source\",directed=False)\n",
    "# print(subset)\n",
    "# # subset, _, mapping, edge_mask = k_hop_subgraph(\n",
    "# #     [1], 2, edge_index,flow=\"source_to_target\",directed=False)\n",
    "# # print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_tgt_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_to_src_subset, tgt_to_src_edge_index, _, tgt_to_src_edge_mask = k_hop_subgraph(\n",
    "            node_idx=1, num_hops=2, edge_index=generator.graph.edge_index,\n",
    "            relabel_nodes=False, flow='target_to_source', directed=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_to_src_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_node_centric_k_hop_subgraph(graph=generator.graph, sample_id=1, num_hops=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
